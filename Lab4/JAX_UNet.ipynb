{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsRPo5ZE8fzx"
      },
      "source": [
        "## U-Net for Image Segmentation with JAX\n",
        "\n",
        "This Colab notebook guides you through building and training a U-Net architecture using JAX for image segmentation tasks, emphasizing the use of `jax.jit` for performance optimization.\n",
        "\n",
        "**Understanding U-Net Architecture**\n",
        "\n",
        "U-Net is a convolutional neural network architecture specifically designed for image segmentation. Its unique U-shaped structure allows it to excel at capturing both local details (fine-grained features) and contextual information  (the broader picture) within an image.  Here's how it works:\n",
        "\n",
        "* **Contracting Path (Encoder):**\n",
        "    * Consists of multiple down-convolution blocks. Each block applies a series of convolutional layers followed by an activation function (e.g., ReLU).\n",
        "    * Down-convolution layers, often with pooling operations (like max pooling), progressively reduce the spatial resolution of the input image while increasing the channels (feature maps). These extracted features become increasingly complex and high-level.\n",
        "\n",
        "* **Expansive Path (Decoder):**\n",
        "    * Composed of up-convolution blocks that utilize transposed convolutions to increase spatial resolution while decreasing channel depth.\n",
        "    * Each block upsamples the feature maps, combining them with skip connections from the corresponding level in the contracting path.\n",
        "    * Skip connections concatenate higher-resolution feature maps from the encoder with the expanded feature maps from the decoder. This helps recover precise localization details lost during downsampling.\n",
        "\n",
        "* **Output Layer:**\n",
        "    * A final convolutional layer, often with a sigmoid activation function, generates the segmentation output(s). This output typically  has the same dimensions as the input image.\n",
        "\n",
        "**The benefits of this architecture make U-Net highly effective for various image segmentation tasks.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PT5R9O-8ply"
      },
      "source": [
        "**1. Setting Up and Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJVe5X7N3hTS"
      },
      "outputs": [],
      "source": [
        "!pip install dm-haiku -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fSr1GxO8fz0"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "\n",
        "# Additional libraries you might need based on your dataset (e.g., for loading and preprocessing)\n",
        "# ...\n",
        "import haiku as hk\n",
        "import jax.nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjF3TvHT8fz1"
      },
      "source": [
        "**2. Defining the U-Net Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShEgtoH18fz1"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def conv_layer(inputs, filters, kernel_size, padding='same'):\n",
        "  \"\"\"\n",
        "  Defines a single convolutional layer with ReLU activation and batch normalization.\n",
        "\n",
        "  Args:\n",
        "    inputs: Input tensor (e.g., image data).\n",
        "    filters: Number of filters in the convolutional layer.\n",
        "    kernel_size: Size of the convolutional kernel.\n",
        "    padding: Padding strategy for the convolution ('same' or 'valid').\n",
        "\n",
        "  Returns:\n",
        "    Output tensor after applying convolution, ReLU activation, and batch normalization.\n",
        "  \"\"\"\n",
        "  # Apply convolution\n",
        "  conv = hk.Conv2D(filters, kernel_size, padding = padding)(inputs)\n",
        "\n",
        "  # Apply ReLU activation (optional)\n",
        "  activated = jax.nn.relu(conv)\n",
        "\n",
        "  # Apply batch normalization (optional)\n",
        "  normalized = hk.BatchNorm()(activated)\n",
        "\n",
        "  return normalized\n",
        "\n",
        "@jax.jit\n",
        "def conv_block(inputs, filters, kernel_size):\n",
        "  \"\"\"Defines a convolutional block with activation and normalization (jitted).\"\"\"\n",
        "  # ... implement convolutional layers, ReLU activation, and batch normalization\n",
        "\n",
        "  conv1 = conv_layer(inputs, filters, kernel_size)\n",
        "  conv2 = conv_layer(conv1, filters, kernel_size)\n",
        "  output = conv2\n",
        "\n",
        "  return output\n",
        "\n",
        "@jax.jit\n",
        "def encoder_block(inputs, filters, kernel_size):\n",
        "  \"\"\"Defines an encoder block with downsampling and skip connection (jitted).\"\"\"\n",
        "  # ... apply two convolutional blocks\n",
        "  conv = conv_block(inputs, filters, kernel_size)\n",
        "  skip_connection = conv\n",
        "\n",
        "  down_sampled = hk.MaxPool((2, 2))(conv)  # apply max pooling for downsampling\n",
        "\n",
        "  return down_sampled, skip_connection\n",
        "\n",
        "@jax.jit\n",
        "def decoder_block(inputs, skip_connection, filters, kernel_size):\n",
        "  \"\"\"Defines a decoder block with upsampling and skip connection (jitted).\"\"\"\n",
        "  # ... apply transposed convolution for upsampling\n",
        "  t_conv = hk.Conv2DTranspose(filters, kernel_size, stride = 2, padding = 'same')(inputs)\n",
        "\n",
        "  # ... concatenate with skip connection from encoder\n",
        "  concatenated = jnp.concatenate([t_conv, skip_connection], axis=-1)\n",
        "\n",
        "  # ... apply two convolutional blocks\n",
        "  conv = conv_block(concatenated, filters, kernel_size)\n",
        "  outputs = conv\n",
        "\n",
        "  return outputs\n",
        "\n",
        "@jax.jit\n",
        "def unet(inputs, filters, kernel_size):\n",
        "  \"\"\"Defines the U-Net architecture (jitted).\"\"\"\n",
        "  # ... create encoder blocks with increasing filter depth\n",
        "  # Encoder\n",
        "  enc1, skip1 = encoder_block(inputs, filters, kernel_size)\n",
        "  enc2, skip2 = encoder_block(enc1, filters*2, kernel_size)\n",
        "  enc3, skip3 = encoder_block(enc2, filters*4, kernel_size)\n",
        "\n",
        "  # Bottom\n",
        "  bottom = conv_block(enc3, filters*8, kernel_size)\n",
        "\n",
        "  # ... create decoder blocks with decreasing filter depth\n",
        "  # Decoder\n",
        "  dec1 = decoder_block(bottom, skip3, filters*4, kernel_size)\n",
        "  dec2 = decoder_block(dec1, skip2, filters*2, kernel_size)\n",
        "  dec3 = decoder_block(dec2, skip1, filters, kernel_size)\n",
        "\n",
        "  # ... apply final convolution for regression output (e.g., 4 channels for tumor segmentation)\n",
        "  outputs = conv_layer(dec3, 4, 1)\n",
        "\n",
        "  return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuLBD8Yu8fz1"
      },
      "source": [
        "**3. Data Acquisition and Preprocessing:**\n",
        "\n",
        "* Download the BraTS 2020 dataset from [https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation](https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation).\n",
        "* Preprocess the data by:\n",
        "    * Resizing images to a fixed size suitable for your model.\n",
        "    * Normalizing pixel intensities (e.g., scaling between 0 and 1).\n",
        "    * Segmenting the brain region using provided masks if necessary.\n",
        "    * Splitting the data into training, validation, and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_2LGV4u_610"
      },
      "outputs": [],
      "source": [
        "def load_data(image_folder):\n",
        "    image_paths = sorted([os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith('.tif')])\n",
        "\n",
        "    images = [cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) for img_path in image_paths]\n",
        "\n",
        "    return jnp.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ykG256G_-YV"
      },
      "outputs": [],
      "source": [
        "def preprocess_images(images):\n",
        "    # Resize images to a fixed size suitable for your model\n",
        "    resized_images = [cv2.resize(img, (256, 256)) for img in images]\n",
        "    # Convert images to grayscale\n",
        "    grayscale_images = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in resized_images]\n",
        "    # Normalize pixel intensities (scaling between 0 and 1)\n",
        "    normalized_images = [img / 255.0 for img in grayscale_images]\n",
        "    return jnp.array(normalized_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7wBwoRN8fz2"
      },
      "outputs": [],
      "source": [
        "# Load your image segmentation dataset (modify accordingly)\n",
        "# ...\n",
        "image_folder = \"datasets/images\"\n",
        "mask_folder = \"datasets/masks\"\n",
        "\n",
        "# Load data\n",
        "images = load_data(image_folder)\n",
        "masks = load_data(mask_folder)\n",
        "\n",
        "# Preprocess data\n",
        "processed_images = preprocess_images(images)\n",
        "processed_masks = preprocess_images(masks)\n",
        "\n",
        "# Preprocess data (normalize and resize). Then split into train, test and validation:\n",
        "\n",
        "# Split into train and validation:\n",
        "train_images, test_images, train_masks, test_masks = train_test_split(processed_images,\n",
        "                                                                    processed_masks,\n",
        "                                                                    test_size=0.2,\n",
        "                                                                    random_state=42)\n",
        "\n",
        "# If you want to further split the training set into training and testing sets, you can do so like this:\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(train_images,\n",
        "                                                                      train_masks,\n",
        "                                                                      test_size=0.2,\n",
        "                                                                      random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cmWwtPA8fz2"
      },
      "source": [
        "**4. Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 0.001\n",
        "epochs = 50\n",
        "\n",
        "# Initialize model parameters\n",
        "key = random.PRNGKey(0)\n",
        "\n",
        "input_shape = (1, 256, 256, 1)\n",
        "unet_model = hk.transform(unet)\n",
        "params = unet_model.init(key, jnp.zeros(input_shape, jnp.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss function (e.g., mean squared error for each segmentation channel)\n",
        "def loss_fn(params, images, masks):\n",
        "    logits = unet_model.apply(params, None, images)\n",
        "    return jnp.mean((logits - masks)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def train_step(params, images, masks):\n",
        "  \"\"\"Training step with jitted loss and gradient calculation (jitted).\"\"\"\n",
        "  # ... calculate loss and gradients\n",
        "  # ... update model parameters using SGD optimizer\n",
        "\n",
        "  grad_fn = jax.grad(loss_fn)\n",
        "  grads = grad_fn(params, images, masks)\n",
        "  updated_params = jax.tree_multimap(lambda p, g: p - learning_rate * g, params, grads)\n",
        "\n",
        "  return updated_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEg0A1UZ8fz2"
      },
      "outputs": [],
      "source": [
        "# Assuming train_images and train_masks are defined and preprocessed\n",
        "for epoch in range(epochs):\n",
        "  # ... training loop using train_step function\n",
        "  # ... (consider logging training progress or visualizing intermediate results)\n",
        "\n",
        "  for i in range(0, len(train_images), 32):\n",
        "          batch_images = train_images[i:i+32]\n",
        "          batch_masks = train_masks[i:i+32]\n",
        "\n",
        "          params = train_step(params, batch_images, batch_masks)\n",
        "\n",
        "          if i % 100 == 0:\n",
        "              loss_value = loss_fn(params, batch_images, batch_masks)\n",
        "              print(f\"Epoch {epoch}, Step {i}, Loss: {loss_value}\")\n",
        "\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTgGCmGq8fz3"
      },
      "source": [
        "**5. Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LISqRLzZod-S"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def dice_coefficient(pred, target):\n",
        "    \"\"\"Compute Dice coefficient.\"\"\"\n",
        "    intersection = jnp.sum(pred * target)\n",
        "    union = jnp.sum(pred) + jnp.sum(target)\n",
        "    return (2. * intersection) / (union + 1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def jaccard_index(pred, target):\n",
        "    \"\"\"Compute Jaccard index.\"\"\"\n",
        "    intersection = jnp.sum(pred * target)\n",
        "    union = jnp.sum(pred) + jnp.sum(target) - intersection\n",
        "    return (intersection) / (union + 1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def evaluate(params, images, masks):\n",
        "  \"\"\"Evaluation with jitted metric calculation (jitted).\"\"\"\n",
        "  logits = unet_model.apply(params, None, images)\n",
        "\n",
        "  # Convert logits to binary predictions\n",
        "  predictions = jnp.argmax(logits, axis=-1)\n",
        "  predictions = jax.nn.one_hot(predictions, 4)\n",
        "\n",
        "  # Compute metrics for each segmentation channel\n",
        "  dice_scores = jnp.array([dice_coefficient(predictions[:, :, :, i], masks[:, :, :, i]) for i in range(4)])\n",
        "  jaccard_scores = jnp.array([jaccard_index(predictions[:, :, :, i], masks[:, :, :, i]) for i in range(4)])\n",
        "\n",
        "  return {\"Dice\": dice_scores, \"Jaccard\": jaccard_scores}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBLa5R2t8fz3"
      },
      "outputs": [],
      "source": [
        "val_metrics = evaluate(params, val_images, val_masks)\n",
        "print(f\"Validation metrics: {val_metrics}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization function\n",
        "def visualize_results(images, masks, predictions, num_samples=5):\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 15))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        axes[i, 0].imshow(images[i].squeeze(), cmap='gray')\n",
        "        axes[i, 0].set_title(\"Input Image\")\n",
        "        axes[i, 0].axis(\"off\")\n",
        "\n",
        "        axes[i, 1].imshow(masks[i].squeeze(), cmap='gray')\n",
        "        axes[i, 1].set_title(\"True Mask\")\n",
        "        axes[i, 1].axis(\"off\")\n",
        "\n",
        "        axes[i, 2].imshow(predictions[i].squeeze(), cmap='gray')\n",
        "        axes[i, 2].set_title(\"Predicted Mask\")\n",
        "        axes[i, 2].axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming params and test_images are defined\n",
        "test_logits = unet_model.apply(params, None, test_images)\n",
        "test_predictions = jnp.argmax(test_logits, axis=-1)\n",
        "visualize_results(test_images[:5], test_masks[:5], test_predictions[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA7_50cJ8fz3"
      },
      "source": [
        "**6. Summary and Next Steps**\n",
        "\n",
        "This notebook provides a foundation for building and training a U-Net model with JAX for image segmentation while emphasizing the importance of `jax.jit` for performance optimization. Remember to:\n",
        "\n",
        "* Replace the placeholders in the code with appropriate JAX operations and functions based on your chosen dataset and architecture details.\n",
        "* Experiment with different hyperparameters (learning rate, filters, etc.) and training strategies to improve the model's performance.\n",
        "* Explore advanced techniques like data augmentation and regularization to enhance modelgeneralizability and robustness.\n",
        "\n",
        "By completing this notebook and understanding the U-Net architecture, you can gain valuable practical experience in building and training deep learning models for image segmentation tasks using JAX effectively."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
